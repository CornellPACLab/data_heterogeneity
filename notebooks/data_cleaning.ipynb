{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "from importlib import reload\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '../code/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import util\n",
    "import cleaning_util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CrossCheck Daily Data Feature Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload data\n",
    "daily_data = pd.read_csv('path/to/crosscheck/daily/data/file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepping\n",
    "daily_data['date'] = pd.to_datetime(daily_data['day'], format='%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get potential features\n",
    "feature_cols = [f for f in daily_data.columns.values if f not in \\\n",
    "                    ['study_id', 'eureka_id', 'day', 'date']]\n",
    "ema_cols = [f for f in feature_cols if 'ema' in f]\n",
    "behavior_cols = [f for f in feature_cols if 'ema' not in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Sort\n",
    "daily_data = daily_data.sort_values(['study_id', 'date']).reset_index(drop=True)\n",
    "# Copy over EMA columns\n",
    "crosscheck_df = daily_data[['study_id', 'eureka_id', 'date'] + ema_cols].copy()\n",
    "for f in behavior_cols:\n",
    "    crosscheck_df[f] = None\n",
    "# Add a column to collect missing days of data\n",
    "crosscheck_df['missing_days'] = 0\n",
    "\n",
    "# Go through each study ID\n",
    "curr = 0\n",
    "for s in daily_data.study_id.unique():\n",
    "    if (curr % 1) == 0:\n",
    "        print(curr)\n",
    "    # Go through each EMA date, discarding the first EMA taken\n",
    "    for ind in daily_data.loc[\n",
    "        (daily_data.study_id == s) & (pd.isnull(daily_data[ema_cols]).sum(axis=1) == 0), :].index[1:]:\n",
    "        # Get date\n",
    "        d = daily_data.loc[ind, 'date']\n",
    "        # Now see if data exists in other df\n",
    "        start_date = d - timedelta(days=2)\n",
    "        end_date = d\n",
    "        filtered_df = daily_data.loc[\n",
    "            (daily_data.study_id == s) & (daily_data.date >= start_date) & (daily_data.date <= end_date), :\n",
    "        ]\n",
    "        if filtered_df.shape[0] > 0:\n",
    "            # Get mean\n",
    "            crosscheck_df.loc[ind, behavior_cols] = filtered_df[behavior_cols].mean().values\n",
    "            # Check for null values across all columns\n",
    "        crosscheck_df.loc[ind, 'missing_days'] = 3 - filtered_df.shape[0]\n",
    "        \n",
    "    curr += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all rowss where there is not EMA data\n",
    "crosscheck_df_cleaned = crosscheck_df.dropna(subset=ema_cols)\n",
    "# Drop all rows where this is no behavioral data and no missing data was marked\n",
    "# These should be the first EMA\n",
    "crosscheck_df_cleaned = crosscheck_df_cleaned.loc[~(\n",
    "        (pd.isnull(crosscheck_df_cleaned[behavior_cols]).sum(axis=1) == len(behavior_cols)) & \\\n",
    "        (crosscheck_df_cleaned.missing_days < 3)\n",
    "    ), :\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crosscheck_df_cleaned.to_csv('../data/crosscheck_daily_data_cleaned_w_sameday.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StudentLife Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EMA Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "studentlife_server_loc = 'path/to/raw/studentlife/folder'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ema_social_files = util.upload_directory(\n",
    "    studentlife_server_loc + '/studentlife/dataset/EMA/response/Social/',\n",
    "    file_type='json'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ema_stress_files = util.upload_directory(\n",
    "    studentlife_server_loc + '/studentlife/dataset/EMA/response/Stress/',\n",
    "    file_type='json'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ema_sleep_files = util.upload_directory(\n",
    "    studentlife_server_loc + '/studentlife/dataset/EMA/response/Sleep/',\n",
    "    file_type='json'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ema_behavior_files = util.upload_directory(\n",
    "    studentlife_server_loc + '/studentlife/dataset/EMA/response/Behavior/',\n",
    "    file_type='json'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ema_mood_files = util.upload_directory(\n",
    "    studentlife_server_loc + '/studentlife/dataset/EMA/response/Mood/',\n",
    "    file_type='json'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ema_pam_files = util.upload_directory(\n",
    "    studentlife_server_loc + '/studentlife/dataset/EMA/response/PAM/',\n",
    "    file_type='json'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prep EMA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make dfs from EMA data\n",
    "ema_mood_df = cleaning_util.prep_studentlife_df(ema_mood_files)\n",
    "ema_social_df = cleaning_util.prep_studentlife_df(ema_social_files)\n",
    "ema_stress_df = cleaning_util.prep_studentlife_df(ema_stress_files)\n",
    "ema_sleep_df = cleaning_util.prep_studentlife_df(ema_sleep_files)\n",
    "ema_behavior_df = cleaning_util.prep_studentlife_df(ema_behavior_files)\n",
    "ema_pam_df = cleaning_util.prep_studentlife_df(ema_pam_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "studentlife_ema_df = cleaning_util.prep_ema_data(\n",
    "    [ema_mood_df, ema_social_df, ema_stress_df, ema_sleep_df, ema_behavior_df, ema_pam_df]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "studentlife_ema_df.to_csv('../data/studentlife_ema_df_01192020.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "studentlife_ema_df = pd.read_csv('../data/studentlife_ema_df_01192020.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prep behavior files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "studentlife_server_loc = 'path/to/raw/studentlife/folder'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "activity_files = util.upload_directory(studentlife_server_loc + '/studentlife/dataset/sensing/activity/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_files = util.upload_directory(studentlife_server_loc + '/studentlife/dataset/sensing/conversation/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gps_files = util.upload_directory(studentlife_server_loc + '/studentlife/dataset/sensing/gps/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phone_lock_files = util.upload_directory(studentlife_server_loc + '/studentlife/dataset/sensing/phonelock/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_df = cleaning_util.clean_studentlife_activity(activity_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_df.to_csv('../data/studentlife_activity_03102020.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_df = pd.read_csv('../data/studentlife_activity_03102020.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_df = cleaning_util.clean_studentlife_conversations(conversation_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_df.to_csv('../data/studentlife_conversations_01192020.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Phone unlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlock_df = cleaning_util.clean_studentlife_unlock(phone_lock_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlock_df.to_csv('../data/studentlife_unlock_08282021.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GPS location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gps_df = cleaning_util.clean_studentlife_location(gps_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gps_df.to_csv('../data/studentlife_gps_01192020.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_df = cleaning_util.clean_sleep_data(\n",
    "    phone_lock_files, cutoff_duration=15, start_time=23, ema_df=studentlife_ema_df,\n",
    "    correction='median'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_df.to_csv('../data/studentlife_sleep_03192020.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get \"good days\" >= 19 hours of day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_days = cleaning_util.get_good_days(dfs=activity_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_days.to_csv('../data/studentlife_good_days_03192020.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StudentLife Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_df = pd.read_csv('../data/studentlife_activity_03102020.csv')\n",
    "unlock_df = pd.read_csv('../data/studentlife_unlock_08282021.csv')\n",
    "conversation_df = pd.read_csv('../data/studentlife_conversations_01192020.csv')\n",
    "gps_df = pd.read_csv('../data/studentlife_gps_01192020.csv')\n",
    "sleep_df = pd.read_csv('../data/studentlife_sleep_03192020.csv')\n",
    "\n",
    "# Good days of data\n",
    "good_days = pd.read_csv('../data/studentlife_good_days_03192020.csv')\n",
    "\n",
    "activity_df['day'] = pd.to_datetime(activity_df['day']).astype(str)\n",
    "unlock_df['day'] = pd.to_datetime(unlock_df['day']).astype(str)\n",
    "conversation_df['day'] = pd.to_datetime(conversation_df['day']).astype(str)\n",
    "gps_df['day'] = pd.to_datetime(gps_df['day']).astype(str)\n",
    "sleep_df['day'] = pd.to_datetime(sleep_df['day']).astype(str)\n",
    "good_days['day'] = pd.to_datetime(good_days['day']).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [studentlife_ema_df, activity_df, conversation_df, gps_df, sleep_df, unlock_df]\n",
    "\n",
    "merged_df = good_days[['study_id', 'day']].copy()\n",
    "for df in dfs:\n",
    "    if merged_df is None:\n",
    "        merged_df = df.copy()\n",
    "    else:\n",
    "        merged_df = pd.merge(left=merged_df, right=df, on=['study_id', 'day'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv('../data/studentlife_daily_data_08282021.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StudentLife prep for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.read_csv('../data/studentlife_daily_data_08282021.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sl_daily_df = merged_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sl_daily_df['day'] = pd.to_datetime(sl_daily_df['day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get potential features\n",
    "sl_feature_cols = [f for f in sl_daily_df.columns.values if f not in ['study_id', 'day']]\n",
    "sl_ema_cols = [f for f in sl_feature_cols if 'ema' in f]\n",
    "sl_behavior_cols = [f for f in sl_feature_cols if 'ema' not in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Sort\n",
    "sl_daily_df = sl_daily_df.sort_values(['study_id', 'day']).reset_index(drop=True)\n",
    "# Copy over EMA columns\n",
    "sl_df = sl_daily_df[['study_id', 'day'] + sl_ema_cols].copy()\n",
    "for f in sl_behavior_cols:\n",
    "    sl_df[f] = None\n",
    "# Add a column to collect missing days of data\n",
    "sl_df['missing_days'] = 0\n",
    "\n",
    "# Go through each study ID\n",
    "curr = 0\n",
    "\n",
    "keep_index = []\n",
    "\n",
    "for s in sl_daily_df.study_id.unique():\n",
    "    if (curr % 1) == 0:\n",
    "        print(curr)\n",
    "    # Go through each EMA date, discarding the first EMA taken\n",
    "    for ind in sl_daily_df.loc[\n",
    "        (sl_daily_df.study_id == s) &\n",
    "        (((~pd.isnull(sl_daily_df[sl_ema_cols])).sum(axis=1)) > 0), :\n",
    "    ].index[1:]:\n",
    "        # Get date\n",
    "        d = sl_daily_df.loc[ind, 'day']\n",
    "        # Now see if data exists in other df\n",
    "        start_date = d - timedelta(days=2)\n",
    "        end_date = d\n",
    "        filtered_df = sl_daily_df.loc[\n",
    "            (sl_daily_df.study_id == s) & (sl_daily_df.day >= start_date) & \\\n",
    "            (sl_daily_df.day <= end_date), :\n",
    "        ]\n",
    "        if filtered_df.shape[0] > 0:\n",
    "            # Get mean\n",
    "            sl_df.loc[ind, sl_behavior_cols] = filtered_df[sl_behavior_cols].mean().values\n",
    "            # Check for null values across all columns\n",
    "        sl_df.loc[ind, 'missing_days'] = 3 - filtered_df.shape[0]\n",
    "        \n",
    "    curr += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all rows where this is no behavioral data and no missing data was marked\n",
    "sl_df_cleaned = sl_df.copy()\n",
    "# These should be the first EMA\n",
    "sl_df_cleaned = sl_df_cleaned.loc[~(\n",
    "        (pd.isnull(sl_df_cleaned[sl_behavior_cols]).sum(axis=1) == len(sl_behavior_cols)) & \\\n",
    "        (sl_df_cleaned.missing_days < 3)\n",
    "    ), :\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sl_df_cleaned.to_csv('../data/studentlife_daily_data_cleaned_w_sameday_08282021.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
